<!DOCTYPE html>
<!--[if lt IE 8 ]><html class="no-js ie ie7" lang="en"> <![endif]-->
<!--[if IE 8 ]><html class="no-js ie ie8" lang="en"> <![endif]-->
<!--[if (gte IE 8)|!(IE)]><!--><html class="no-js" lang="en"> <!--<![endif]-->
<head>

   <!--- Basic Page Needs
   ================================================== -->
  <meta charset="utf-8">
	<title>Yang Zhang</title>
	<meta name="description" content="Research and Personal Projects">
	<meta name="author" content="">

   <!-- Mobile Specific Metas
   ================================================== -->
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<!-- CSS
    ================================================== -->
   <link rel="stylesheet" href="css/default.css">
	 <link rel="stylesheet" href="css/layout.css">
   <link rel="stylesheet" href="css/academicons/css/academicons.css"/>
   <link rel="stylesheet" href="css/media-queries.css">
   <link rel="stylesheet" href="css/magnific-popup.css">

   <!-- Script
   ================================================== -->
	<script src="js/modernizr.js"></script>


</head>

<body>


   <!-- About Section
   ================================================== -->
   <section id="about">
      <nav id="nav-wrap">

        <a class="mobile-btn" href="#nav-wrap" title="Show navigation">Show navigation</a>
	      <a class="mobile-btn" href="#" title="Hide navigation">Hide navigation</a>

         <ul id="nav" class="nav">
            <li class="current"><a class="smoothscroll" href="#about">About</a></li>
            <li><a class="smoothscroll" href="#publication">Publications</a></li>
	    <li><a class="smoothscroll" href="#experience">Experiences</a></li>
	    <li><a class="smoothscroll" href="#activity">Activities</a></li>
            <li><a class="smoothscroll" href="#teaching">Teaching</a></li>
            <li><a class="smoothscroll" href="#award">Awards</a></li>

         </ul> <!-- end #nav -->

      </nav> <!-- end #nav-wrap -->

      <div class="row">

         <div class="three columns">

            <img class="profile-pic"  src="media/Yangzhang.jpg" alt="" />

         </div>

         <div class="nine columns main-col">

            <h1><font color="white">Yang Zhang</font></h1>

            <h5> <font color="white"> Ph.D., Computer Vision and Multimedia @ NJU </font> </h5>
            <!-- <h5> <font color="white"> National Key Laboratory for Novel Software Technology </font> </h5> -->
            <h5> <font color="white"> Associate Professor @ School of Mechanical Engineering, Hubei University of Technology </font> </h5>
		 <font color="white"> yzhangcst[at]gmail.com; yzhangcst[at]hbut.edu.cn </font>
            <footer>
              <div class="row">

               <div class="twelve columns">
                  <ul class="social-links">
                     <li><a href="https://scholar.google.com/citations?user=lgXDV5cAAAAJ&hl=zh-CN&citsig=AMD79oorCUy1KxBXSEYZK76Eo9el2mvzGA" target="_blank" title="Google Scholar"><i class="fa fa-google" style="zoom:80%"></i></a></li>
                     <li><a href="https://github.com/Yangzhangcst" target="_blank" title="Github"><i class="fa fa-github" style="zoom:80%"></i></a></li>
		     <li><a href="https://www.researchgate.net/profile/Yang_Zhang151" target="_blank" title="Researchgate"><i class="fa fa-group" style="zoom:80%"></i></a></li>	
	             <li><a href="https://dblp.org/pid/06/6785-53.html" target="_blank" title="DBLP"><i class="fa fa-user-circle" style="zoom:80%"></i></a></li>	  
		     <li><a href="images/Wechat.jpg" target="_blank" title="Wechat"><i class="fa fa-wechat" style="zoom:80%"></i></a></li>
                  </ul>
               </div>
              </div> <!-- end #row-->
            </footer>
         </div> <!-- end #main-col-->

     </div> <!-- end #row-->
     <p class="scrolldown">
         <a class="smoothscroll" href="#about"><i class="icon-down-circle"></i></a>
      </p>

   
<section id="teaser">

 <div class="row add-bottom">
   <p align="justify" class="lead">
	I am currently an Associate Professor at <a href="https://tsme.hbut.edu.cn/info/1013/3776.htm" target="_blank" title="CV1"> 
	   School of Mechanical Engineering</a>, Hubei University of Technology, China. My current research interests are machine learning and computer vision including 2D & 3D scene understanding.
	   My full Chinese CV is available <a href="media/CV.pdf" target="_blank" title="CV2"> here. </a> </p>
   <p>
        I was previously a Postdoctoral Fellow from <a href="http://www.labren.org/mm/">Medical Robotics Perception & AI </a> at The Chinese University of Hong Kong. I received the Ph.D. degree from the National Key Laboratory for Novel Software Technology, 
	   Department of Computer Science and Technology, Nanjing University with <a href="http://www.njumeta.com/">Yanwen Guo</a> in 2021. 
	  </p>	
	 
 </div> 
	 
   <!--Publication Section
   ================================================== -->
   <section id="publication">

    <div class="row add-bottom">

         <div class="twelve columns">

            <h1 align="center">Selected Publications<a href="./paper-list.html" 
					      target="_blank" title="full lists"><i class="fa fa-link"></i></a></h1>
            <hr>
            <div class="row add-bottom">
              <h2 align=center> <font color="black"> Spatial-wise Dynamic Distillation for MLP-like Efficient Visual Fault Detection of Freight Trains </font> </h2>
	      <h5 align=center> <font color="black"> IEEE Transactions on Industrial Electronics, 2024 </font> </h3>

              <p align="center", class="lead add-bottom">
                Yang Zhang, Huilin Pan, Mingying Li, An Wang, Yang Zhou, Hongliang Ren
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/TIE-2024.png" >
                  </div>
                    <div class="seven columns">
                      <p align="justify" class="add-bottom">
                         Spatial-wise dynamic distillation framework based on multi-layer perceptron (MLP) Is designed for visual fault detection of freight trains. 
			      We initially present the axial shift strategy, which allows the MLP-like architecture to overcome the challenge of spatial invariance and 
			      effectively incorporate both local and global cues. We propose a dynamic distillation method without a pre-training teacher, including a 
			      dynamic teacher mechanism that can effectively eliminate the semantic discrepancy with the student model. Such an approach mines more abundant 
			      details from lower-level feature appearances and higher-level label semantics as the extra supervision signal, which utilizes efficient instance 
			      embedding to model the global spatial and semantic information.
                      </p>
                      <p class="paper-links" align="left"> 
                        <a href="https://github.com/MVME-HBUT/SDD-FTI-FDet" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://arxiv.org/pdf/2312.05832.pdf" target="_blank" title="Paper-arxiv"><i class="fa fa-file-pdf-o"></i></a>
			<a href="https://ieeexplore.ieee.org/document/10391271/" target="_blank" title="Paper-IEEE"><i class="fa fa-file-pdf-o"></i></a>
                      </p>
                    </div>
                </div>
	    </div>
            <div class="row add-bottom">
              <h2 align=center> <font color="black"> An Efficient MLP-based Point-guided Segmentation Network for Ore Images with Ambiguous Boundary </font> </h2>
	      <h5 align=center> <font color="black"> IEEE Transactions on Industrial Informatics, 2024 </font> </h3>

              <p align="center", class="lead add-bottom">
                Guodong Sun, Yuting Peng, Le Cheng, Mengya Xu, An Wang, Bo Wu, Hongliang Ren, Yang Zhang*
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/TII-2024-ORE.png" >
                  </div>
                    <div class="seven columns">
                      <p align="justify" class="add-bottom">
                         Due to the homogeneous appearance of the ores, which leads to low contrast and unclear boundaries, accurate segmentation becomes challenging, 
			      and recognition becomes problematic. This paper proposes a lightweight framework based on Multi-Layer Perceptron (MLP), which focuses 
			      on solving the problem of edge burring.  Specifically, we introduce a lightweight backbone better suited for efficiently extracting 
			      low-level features. Besides, we design a feature pyramid network consisting of two MLP structures that balance local and global 
			      information thus enhancing detection accuracy. Furthermore, we propose a novel loss function that guides the prediction points to 
			      match the instance edge points to achieve clear object boundaries.
                      </p>
                      <p class="paper-links" align="left"> 
                        <a href="https://github.com/MVME-HBUT/ORENEXT" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://arxiv.org/pdf/2402.17370.pdf" target="_blank" title="Paper-arxiv"><i class="fa fa-file-pdf-o"></i></a>
			<!a href="https://www.sciencedirect.com/science/article/pii/S0952197623016743" target="_blank" title="Paper-Elsevier"><i class="fa fa-file-pdf-o"></i></a>
                      </p>
                    </div>
                </div>
	    </div>
            <div class="row add-bottom">
              <h2 align=center> <font color="black"> Efficient segmentation with texture in ore images based on box-supervised approach </font> </h2>
	      <h5 align=center> <font color="black"> Engineering Applications of Artificial Intelligence, 2024 </font> </h3>

              <p align="center", class="lead add-bottom">
                Guodong Sun, Delong Huang, Yuting Peng, Le Cheng, Bo Wu, Yang Zhang*
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/EAAI-2023.jpg" >
                  </div>
                    <div class="seven columns">
                      <p align="justify" class="add-bottom">
                         An effective box-supervised technique with texture features is provided for ore image segmentation that can identify complete 
			      and independent ores. Firstly, a ghost feature pyramid network (Ghost-FPN) is proposed to process the features obtained from the backbone to reduce 
			      redundant semantic information and computation generated by complex networks. Then, an optimized detection head is proposed to obtain the feature 
			      to maintain accuracy. Finally, Lab color space (Lab) and local binary patterns (LBP) texture features are combined to form a 
			      fusion feature similarity-based loss function to improve accuracy while incurring no loss. 
                      </p>
                      <p class="paper-links" align="left"> 
                        <a href="https://github.com/MVME-HBUT/OREINST" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://arxiv.org/pdf/2311.05929.pdf" target="_blank" title="Paper-arxiv"><i class="fa fa-file-pdf-o"></i></a>
			<a href="https://www.sciencedirect.com/science/article/pii/S0952197623016743" target="_blank" title="Paper-Elsevier"><i class="fa fa-file-pdf-o"></i></a>
                      </p>
                    </div>
                </div>
	    </div>
            <div class="row add-bottom">
              <h2 align=center> <font color="black"> Efficient Visual Fault Detection for Freight Train Braking System via Heterogeneous Self Distillation in the Wild </font> </h2>
	      <h5 align=center> <font color="black"> Advanced Engineering Informatics, 2023 </font> </h3>

              <p align="center", class="lead add-bottom">
                Yang Zhang, Huilin Pan, Yang Zhou, Mingying Li, and Guodong Sun
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/AdvEI-2023.jpg" >
                  </div>
                    <div class="seven columns">
                      <p align="justify" class="add-bottom">
                         This paper proposes a heterogeneous self-distillation framework to ensure detection accuracy and speed while satisfying low resource requirements. The 
			      privileged information in the output feature knowledge can be transferred from the teacher to the student model through distillation to boost performance. 
			      We first adopt a lightweight backbone to extract features and generate a new heterogeneous knowledge neck. Such neck models positional information and 
			      long-range dependencies among channels through parallel encoding to optimize feature extraction capabilities. Then, we utilize the general distribution 
			      to obtain more credible and accurate bounding box estimates. Finally, we employ a novel loss function that makes the network easily concentrate on values 
			      near the label to improve learning efficiency. 
                      </p>
                      <p class="paper-links" align="left"> 
                        <a href="https://github.com/MVME-HBUT/HSD-FTI-FDet" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://arxiv.org/pdf/2307.00701.pdf" target="_blank" title="Paper-arxiv"><i class="fa fa-file-pdf-o"></i></a>
			<a href="https://www.sciencedirect.com/science/article/abs/pii/S1474034623002197" target="_blank" title="Paper-Elsevier"><i class="fa fa-file-pdf-o"></i></a>
                      </p>
                    </div>
                </div>
	    </div>
            <div class="row add-bottom">
              <h2 align=center> <font color="black"> Spatial-information Guided Adaptive Context-aware Network for Efficient RGB-D Semantic Segmentation </font> </h2>
	      <h5 align=center> <font color="black"> IEEE Sensors Journal, 2023 </font> </h3>

              <p align="center", class="lead add-bottom">
                Yang Zhang, Chenyun Xiong, Junjie Liu, Xuhui Ye, Guodong Sun
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/SenJ-2023.jpg" >
                  </div>
                    <div class="seven columns">
                      <p align="justify" class="add-bottom">
                         This paper proposes an efficient lightweight encoderdecoder network that reduces the computational parameters and 
			      guarantees the robustness of the algorithm. Working with channel and spatial fusion attention modules, our 
			      network effectively captures multi-level RGB-D features. A globally guided local affinity context module is 
			      proposed to obtain sufficient high-level context information. The decoder utilizes a lightweight residual unit 
			      that combines short- and long-distance information with a few redundant computations. Experimental results on 
			      NYUv2, SUN RGB-D, and Cityscapes datasets show that our method achieves a better trade-off among segmentation 
			      accuracy, inference time, and parameters than the state-of-the-art methods.
                      </p>
                      <p class="paper-links" align="left"> 
                        <a href="https://github.com/MVME-HBUT/SGACNet" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://arxiv.org/pdf/2308.06024.pdf" target="_blank" title="Paper-arxiv"><i class="fa fa-file-pdf-o"></i></a>
			<a href="https://ieeexplore.ieee.org/document/10223721" target="_blank" title="Paper-IEEE"><i class="fa fa-file-pdf-o"></i></a>
                      </p>
                    </div>
                </div>
	    </div>
            <div class="row add-bottom">
              <h2 align=center> <font color="black"> Faster OreFSDet: A Lightweight and Effective Few-shot Object Detector for Ore Images </font> </h2>
	      <h5 align=center> <font color="black"> Pattern Recognition, 2023 </font> </h3>

              <p align="center", class="lead add-bottom">
                Yang Zhang, Le Cheng, Yuting Peng, Chengming Xu, Yanwei Fu, Bo Wu, and Guodong Sun
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/PR-2023.jpg" >
                  </div>
                    <div class="seven columns">
                      <p align="justify" class="add-bottom">
                         A lightweight and effective few-shot detector is proposed to achieve competitive performance with general object detection with only a few samples 
			      for ore images. First, the proposed support feature mining block characterizes the importance of location information in 
			      support features. Next, the relationship guidance block makes full use of support features to guide the generation of accurate 
			      candidate proposals. Finally, the dual-scale semantic aggregation module retrieves detailed features at different resolutions 
			      to contribute with the prediction process. Our method achieves the smallest model size of 19MB as well as being competitive at 50 FPS 
			      detection speed compared with general object detectors.
                      </p>
                      <p class="paper-links" align="left"> 
                        <a href="https://github.com/MVME-HBUT/Faster-OreFSDet" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://arxiv.org/pdf/2305.01183.pdf" target="_blank" title="Paper-arxiv"><i class="fa fa-file-pdf-o"></i></a>
			<a href="https://www.sciencedirect.com/science/article/pii/S0031320323003655" target="_blank" title="Paper-Elsevier"><i class="fa fa-file-pdf-o"></i></a>
                      </p>
                    </div>
                </div>
	    </div>
            <div class="row add-bottom">
              <h2 align=center> <font color="black"> Adaptive Fusion Affinity Graph with Noise-free Online Low-rank Representation for Natural Image Segmentation </font> </h2>
	      <h5 align=center> <font color="black"> Pattern Recognition, 2023 </font> </h3>

              <p align="center", class="lead add-bottom">
                Yang Zhang, Moyun Liu, Huiming Zhang, Guodong Sun, and Jingwu He
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/arXiv2021-paper.jpg" >
                  </div>
                    <div class="seven columns">
                      <p align="justify" class="add-bottom">
                        The proposed adaptive fusion affinity graph (AFA-graph) with noise-free low-rank representation in an online manner for natural image segmentation. 
			      An input image is first over-segmented into superpixels at different scales and then filtered by the proposed improved kernel density 
			      estimation method. Moreover, we select global nodes of these superpixels on the basis of their subspace-preserving presentation, which
			      reveals the feature distribution of superpixels exactly. To reduce time complexity while improving performance, a sparse representation 
			      of global nodes based on noise-free online lowrank representation is used to obtain a global graph at each scale. The global graph is 
			      finally used to update a local graph which is built upon all superpixels at each scale.
                      </p>
                      <p class="paper-links" align="left"> 
                        <a href="https://github.com/Yangzhangcst/AFA-graph" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://arxiv.org/pdf/2110.11685.pdf" target="_blank" title="Paper-arxiv"><i class="fa fa-file-pdf-o"></i></a>
			<a href="https://www.sciencedirect.com/science/article/pii/S0031320323003126" target="_blank" title="Paper-Elsevier"><i class="fa fa-file-pdf-o"></i></a>
                      </p>
                    </div>
                </div>
	    </div>
	    <div class="row add-bottom">
              <h2 align=center> <font color="black"> Visual Fault Detection of Multi-scale Key Components in Freight Trains </font> </h2>
	      <h5 align=center> <font color="black"> IEEE Transactions on Industrial Informatics, 2022 </font> </h3>

              <p align="center", class="lead add-bottom">
                Yang Zhang, Yang Zhou, Huilin Pan, Bo Wu, Guodong Sun
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/TII2022-paper.jpg" >
                  </div>
                    <div class="seven columns">
                      <p align="justify" class="add-bottom"> 
			Despite the frequently employed methods based on deep learning, these fault detectors are extremely reliant on hardware resources and complex to implement. 
			      In addition, no train fault detectors consider the drop in accuracy induced by scale variation of fault parts. This paper proposes a lightweight 
			      anchor-free framework to solve the above problems. Specifically, to reduce the amount of computation and model size, we introduce a lightweight 
			      backbone and adopt an anchor-free method for localization and regression. To improve detection accuracy for multi-scale parts, we design a feature 
			      pyramid network to generate rectangular layers of different sizes to map parts with similar aspect ratios.
                      </p>
                      <p class="paper-links" align="left"> 
                        <a href="https://github.com/MVME-HBUT/MS-FTI-FDet" target="_blank" title="Code"><i class="fa fa-github"></i></a>
			<a href="https://arxiv.org/pdf/2211.14522.pdf" target="_blank" title="Paper-arxiv"><i class="fa fa-file-pdf-o"></i></a>
			<a href="https://ieeexplore.ieee.org/document/9964185" target="_blank" title="Paper-ieee"><i class="fa fa-file-pdf-o"></i></a>
                      </p>
                    </div>
                </div>
	    </div>
	    <div class="row add-bottom">
              <h2 align=center> <font color="black"> A Lightweight NMS-free Framework for Real-time Visual Fault Detection System of Freight Trains </font> </h2>
	      <h5 align=center> <font color="black"> IEEE Transactions on Instrumentation and Measurement, 2022, 71: 1-11 </font> </h3>

              <p align="center", class="lead add-bottom">
                Guodong Sun, Yang Zhou, Huilin Pan, Bo Wu, Ye Hu, Yang Zhang*
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/TIM2022-paper.jpg" >
                  </div>
                    <div class="seven columns">
                      <p align="justify" class="add-bottom"> 
			A lightweight NMS-free framework is proposed to achieve real-time detection and high accuracy simultaneously. We use a lightweight backbone for 
			      feature extraction and design a fault detection pyramid toprocess features. This fault detection pyramid includes three novel individual 
			      modules using attention mechanism, bottleneck, and dilated convolution for feature enhancement and computation reduction. Instead of using 
			      NMS, we calculate different loss functions, including classification and location costs in the head to reduce computation.
                      </p>
                      <p class="paper-links" align="left"> 
                        <a href="https://github.com/MVME-HBUT/LosNet" target="_blank" title="Code"><i class="fa fa-github"></i></a>
			<a href="https://arxiv.org/pdf/2205.12458.pdf" target="_blank" title="Paper-arxiv"><i class="fa fa-file-pdf-o"></i></a>
			<a href="https://ieeexplore.ieee.org/document/9779731" target="_blank" title="Paper-ieee"><i class="fa fa-file-pdf-o"></i></a>
                      </p>
                    </div>
                </div>
	    </div>
            <!--div class="row add-bottom">
              <h2 align=center> <font color="black"> Attention-based Dual Supervised Decoder for RGBD Semantic Segmentation </font> </h2>
	      <h5 align=center> <font color="black"> Accepted by Computational Visual Media Conference, 2022  </font> </h3>

              <p align="center", class="lead add-bottom">
                Yang Zhang, Yang Yang, Chenyun Xiong, Guodong Sun, Yanwen Guo
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/CVM2022-paper1.jpg" >
                  </div>
                    <div class="seven columns">
                      <p align="justify" class="add-bottom">
                        Most existing approaches fail to comprehensively utilize multi-modal information in both the encoder and decoder. In this paper, we propose a novel attentionbased dual supervised 
			      decoder for RGBD semantic segmentation. In the encoder, we design a simple yet effective attention-based multi-modal fusion module to extract
			      and fuse deeply multi-level paired complementary information. To learn more robust deep representations and rich multi-modal information, we 
			      introduce a dual-branch decoder to effectively leverage the correlations and complementary cues of different tasks. 
                      </p>
                      <p class="paper-links" align="left"> 
                        <a href="https://arxiv.org/pdf/2201.01427.pdf" target="_blank" title="Paper-arxiv"><i class="fa fa-file-pdf-o"></i></a>
			<!--<a href="https://ieeexplore.ieee.org/document/9334427" target="_blank" title="Paper-ieee"><i class="fa fa-file-pdf-o"></i></a>-->
                      </p>
                    </div>
                </div>
	    </div>	
	    <div class="row add-bottom">
              <h2 align=center> <font color="black"> A Unified Light Framework for Real-time Fault Detection of Freight Train Images </font> </h2>
	      <h5 align=center> <font color="black"> IEEE Transactions on Industrial Informatics, 2021, 17(11): 7423-7432 </font> </h3>

              <p align="center", class="lead add-bottom">
                Yang Zhang, Moyun Liu, Yang Yang, Yanwen Guo, Huiming Zhang
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/TII2021-paper.jpg" >
                  </div>
                    <div class="seven columns">
                      <p align="justify" class="add-bottom"> 
			A unified light framework is designed to improve detection accuracy while supporting a real-time operation 
			      with a low resource requirement. We firstly design a novel lightweight backbone (RFDNet) to improve the accuracy 
			      and reduce computational cost. Then, we propose a multi region proposal network using multi-scale feature maps 
			      generated from RFDNet to improve the detection performance. Finally, we present multi level position-sensitive 
			      score maps and region of interest pooling to further improve accuracy with few redundant computations.
                      </p>
                      <p class="paper-links" align="left"> 
                        <a href="https://github.com/Yangzhangcst/LR-FTI-FDet" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://arxiv.org/pdf/2102.00381.pdf" target="_blank" title="Paper-arxiv"><i class="fa fa-file-pdf-o"></i></a>
			<a href="https://ieeexplore.ieee.org/document/9346044" target="_blank" title="Paper-ieee"><i class="fa fa-file-pdf-o"></i></a>
                      </p>
                    </div>
                </div>
	    </div>
            <div class="row add-bottom">
              <h2 align=center> <font color="black"> Affinity Fusion Graph-based Framework for Natural Image Segmentation </font> </h2>
	      <h5 align=center> <font color="black"> IEEE Transactions on Multimedia, 2022, 24:440-450 </font> </h3>

              <p align="center", class="lead add-bottom">
                Yang Zhang, Moyun Liu, Jingwu He, Fei Pan, Yanwen Guo
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/TMM2021-paper.jpg" >
                  </div>
                    <div class="seven columns">
                      <p align="justify" class="add-bottom">
                        The proposed framework combines adjacency-graphs and kernel spectral clustering based graphs (KSC-graphs) according 
			      to a new definition named affinity nodes of multi-scale superpixels. These affinity nodes are selected based on 
			      a better affiliation of superpixels, namely subspace-preserving representation which is generated by sparse 
			      subspace clustering based on subspace pursuit. Then a KSC-graph is built via a novel kernel spectral clustering 
			      to explore the nonlinear relationships among these affinity nodes. Moreover, an adjacency-graph at each scale is 
			      constructed, which is further used to update the proposed KSC-graph at affinity nodes. The fusion graph is built 
			      across different scales, and it is partitioned to obtain final segmentation result. 
                      </p>
                      <p class="paper-links" align="left"> 
                        <a href="https://github.com/Yangzhangcst/AF-graph" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://arxiv.org/pdf/2006.13542.pdf" target="_blank" title="Paper-arxiv"><i class="fa fa-file-pdf-o"></i></a>
			<a href="https://ieeexplore.ieee.org/document/9334427" target="_blank" title="Paper-ieee"><i class="fa fa-file-pdf-o"></i></a>
                      </p>
                    </div>
                </div>
	    </div>	
            <div class="row add-bottom">
              <h2 align=center> <font color="black"> Real-time Vision Based System of Fault Detection for Freight Trains </font> </h2>
	      <h5 align=center> <font color="black"> IEEE Transactions on Instrumentation and Measurement, 2020, 69(7): 5274-5284 </font> </h3>

              <p align="center", class="lead add-bottom">
                Yang Zhang, Moyun Liu, Yunian Chen, Hongjie Zhang, Yanwen Guo
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/TIM-paper.jpg" >
                  </div>
                    <div class="seven columns">
                      <p align="justify" class="add-bottom">
                        Real-time vision based system of fault detection (RVBS-FD) for freight trains aims to complete routine maintenance 
			      tasks efficiently for ensuring railway security. Recently, the rapid development of deep learning techniques 
			      enables systems to provide a robust solution for the RVBS-FD of freight trains. We propose a CNN-based 
			      detector called Light FTI-FDet for the RVBS-FD of freight train. The results on five typical fault 
			      benchmarks indicate that our Light FTI-FDet achieves higher accuracy and fast speed with about 17% model size of the 
			      well-known Faster R-CNN detector, substantially outperforming state-of-the-art methods.
                      </p>
                      <p class="paper-links" align="left"> 
                        <a href="https://github.com/Yangzhangcst/Light-FTI-FDet" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://ieeexplore.ieee.org/document/8911418" target="_blank" title="Paper"><i class="fa fa-file-pdf-o"></i></a>
                      </p>
                    </div>
                </div>
	    </div>
            <!--div class="row add-bottom">
              <h2 align=center> <font color="black"> An Adaptive Affinity Graph with Subspace Pursuit for Natural Image Segmentation </font> </h2>
	      <h5 align=center> <font color="black"> IEEE International Conference on Multimedia and Expo, 2019 (oral)</font> </h3>
	      <p align="center", class="lead add-bottom">
                Yang Zhang, Huiming Zhang, Yanwen Guo, Kai Lin, Jingwu He
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/ICME-paper.jpg" >
                  </div>
                    <div class="seven columns">
                      <p align="justify" class="add-bottom">
                        Graph-based segmentation methods have become a major trend in computer vision. Due to the advantages of assimilating 
			      different graphs, a multi-scale fusion graph have a better performance than a single graph with single-scale. 
			      However, it is not reliable to determine a principle of graph combination. In this paper, we propose an adaptive 
			      affinity graph with subspace pursuit (AASP-graph) for natural image segmentation. Experimental results on the 
			      Berkeley segmentation database show the effectiveness of the proposed AASP-graph in comparison with 
			      state-of-the-art approaches.
                      </p>
                      <p class="paper-links" align="left"> 
			<a href="media/poster/ICME-poster-v.pdf" target="_blank" title="Poster"><i class="fa fa-file-image-o"></i></a>
			<a href="media/slides/AN ADAPTIVE AFFINITY GRAPH WITH SUBSPACE PURSUIT FOR NATURAL IMAGE.pdf" target="_blank" title="Slide"><i class="fa fa-file-powerpoint-o"></i></a>	
                        <a href="https://github.com/Yangzhangcst/AASP-Graph" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://ieeexplore.ieee.org/document/8784904" target="_blank" title="Paper"><i class="fa fa-file-pdf-o"></i></a></p>
                    </div>
                </div>
            </div>
            <div class="row add-bottom">
              <h2 align=center> <font color="black"> A Unified Framework for Fault Detection of Freight Train Images Under Complex Environment </font> </h2>
	      <h5 align=center> <font color="black"> IEEE International Conference on Image Processing, 2018 </font> </h3>
              <p align="center", class="lead add-bottom">
                Yang Zhang, Kai Lin, Huiming Zhang, Yanwen Guo, Guodong Sun
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/ICIP-paper.jpg" > 
                  </div>
                    <div class="seven columns">
                      <p align="justify" class="add-bottom">
                        This paper proposes a novel unified framework for fault detection of the freight train images based on convolutional
			      neural network under complex environment. Firstly, the multi region proposal networks with a set 
			      of prior bounding boxes are introduced to achieve high quality fault proposal generation. And then, we apply 
			      a linear non-maximum suppression method to retain the most suitable anchor while removing redundant boxes. 
			      Finally, a powerful multi-level region-of-interest pooling is proposed for proposal classification a
			      nd accurate detection. 
                      </p>
                      <p class="paper-links" align="left"> 
			<a href="media/poster/ICIP.jpg" target="_blank" title="Poster"><i class="fa fa-file-image-o"></i></a>
                        <a href="https://github.com/Yangzhangcst/Light-FTI-FDet" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://ieeexplore.ieee.org/document/8451188" target="_blank" title="Paper"><i class="fa fa-file-pdf-o"></i></a></p>
                    </div>
                </div>
            </div>
	    <!--div class="row add-bottom">
              <h2 align=center> <font color="black"> Detection of Tiny Surface Defects on Small Ring Parts Using Normal Maps </font> </h2>
              <h5 align=center> <font color="black"> Pacific-Rim Conference on Multimedia, 2018 (oral)</font> </h3>
	      <p align="center", class="lead add-bottom">
                Yang Zhang, Jia Song, Huiming Zhang, Jingwu He, Yanwen Guo
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/PCM-paper.jpg" >
                  </div>
                    <div class="seven columns">
                      <p align="justify" class="add-bottom">
                        Detection of tiny surface defects on small ring parts remains challeng-ing due to the unnoticeable visual features 
			      of such defects and the interference of small surface scratches. This paper proposes a novel method for 
			      detecting tiny surface defects based on normal maps of metal parts. To better characterize fea-tures of 
			      tiny defects and differentiate them from small scratches, we recover the normal map of the metal part 
			      through analyzing its directional reflections ob-tained with our specifically designed directional light units. 
			      Based on the normal map, a cascaded detector trained by the AdaBoost approach combined with the joint features 
			      and fast feature pyramid is used to localize the defects, achieving fast and accurate detection of tiny surface 
			      defects.
                      </p>
                      <p class="paper-links" align="left"> 
			<a href="media/slides/Tiny Surface Defects on Small Ring Parts using Normal Maps.pdf" target="_blank" title="Slide"><i class="fa fa-file-powerpoint-o"></i></a>
                        <a href="https://github.com/Yangzhangcst" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://link.springer.com/chapter/10.1007%2F978-3-030-00776-8_37" target="_blank" title="Paper"><i class="fa fa-file-pdf-o"></i></a></p>
                    </div>
                </div>
	    </div>	    
	    <!--div class="row add-bottom">
              <h2 align=center> <font color="black"> Railway Equipment Detection Using Exact Height Function Shape Descriptor Based on Fast Adaptive Markov Random Field </font> </h2>
              <h5 align=center> <font color="black"> Optical Engineering, 2018, 57(5): 053114 </font> </h3>
		    <p align="center", class="lead add-bottom">
                Guodong Sun, Yang Zhang, Hanbing Tang, Huiming Zhang, Moyun Liu and Daxing Zhao
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/OE-paper.jpg" >
                  </div>
                    <div class="seven columns">
                      <p align="justify" class="add-bottom">
                        This paper proposes a novel hierarchical feature matching model for the typical faults detection, which is a big 
			      challenge in trouble of moving freight car detection system due to the constant color and complex 
			      background of images. The proposed model divides fault detection into two stages: image segmentation and
			      parallel shape matching.  In the process of segmentation, a fast adaptive Markov random field 
			      segmentation algorithm is presented based on MRF combined with the image Pyramid model and affinity 
			      propagation theory. In the process of shape matching, a novel shape descriptor named exact height function
			      is introduced on the basis of height function description.
                      </p>
                      <p class="paper-links" align="left"> 
                        <!--<a href="https://github.com/Yangzhangcst" target="_blank" title="Code"><i class="fa fa-github"></i></a>-->
                        <!--a href="media/OE-Railway equipment detection.pdf" target="_blank" title="Paper"><i class="fa fa-file-pdf-o"></i></a></p>
                    </div>
                </div>
	    </div>    
            <div class="row add-bottom">
              <h2 align=center> <font color="black"> Hierarchical Feature Matching of Fault Images in TFDS Based on Improved Markov Random Field and Exact Height Function </font> </h2>
              <h5 align=center> <font color="black"> Master's Thesis, Hubei University of Technology (HBUT), 2017 </font> </h5>
              <p align="center", class="lead add-bottom">
                Yang Zhang
              </p>
                    <div class="twelve columns">
                      <p align="justify" class="add-bottom">
                        According to the characteristics of TFDS image, based on hierarchical model and shape matching, hierarchical feature matching algorithm for fault images
			      in TFDS are proposed to achieve automatic recognition of air brake system malfunction, bogie block key missing, the loss of high wear synthetic 
			      brake shoe and the absence of fastening bolts on brake beam. The proposed algorithm achieves high rate and good robustness, and it can be effectively 
			      applied into the fault detection for TFDS images.
                        <a href="https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD&dbname=CMFD201801&filename=1017815200.nh&v=MTEwMThNMUZyQ1VSTE9lWnVkbUZ5N2dWTHpQVkYyNkdidTVHOVBNcjVFYlBJUjhlWDFMdXhZUzdEaDFUM3FUclc="
			   target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
         </div>

      </div> <!-- Row End-->

   </section> <!-- Publication Section End-->
	   
   <section id="experience">

    <div class="row add-bottom">

         <div class="twelve columns">

            <h1 align="center">Experiences</h1>
            <hr>   
  
            <div class="row add-bottom">
                    <div class="twelve columns">
		      <p align="justify" class="add-bottom">
			 Research Intern | Tencent Youtu Lab, Tencent, Shanghai, China | Feb. 2021 – Jun. 2021
			 (Advisor: Yuqiang Ren.  Topic: Object Detection.)
                      </p>   
		      <p align="justify" class="add-bottom"> 
                         Postdoctoral Fellow | The Chinese University of Hong Kong, Hongkong, China | Nov. 2022 – May. 2023.
			 (Advisor: Hongliang Ren.  Topic: Industrial Robot.)
                      </p>    
		    </div>
             </div>
         </div>

      </div> <!-- Row End-->

   </section> <!-- Publication Section End-->

   <section id="activity">

    <div class="row add-bottom">

         <div class="twelve columns">

            <h1 align="center">Activities</h1>
            <hr>   
  
            <div class="row add-bottom">
                    <div class="twelve columns">
		      <p align="justify" class="add-bottom">
			 The reviewer for IEEE Transactions on Industrial Informatics. 
                      </p>    
                      <p align="justify" class="add-bottom">
			 The reviewer for the IEEE International Conference on Robotics and Automation (ICRA2024).
                      </p>
                      <p align="justify" class="add-bottom">
			 The reviewer for Information Fusion, Computers in Biology and Medicine, Computers and Electrical Engineering, and Pattern Recognition Letters.
                      </p>
                      <p align="justify" class="add-bottom">
			 The reviewer for Pattern Recognition, Advanced Engineering Informatics, Engineering Applications of Artificial Intelligence, and Expert Systems with Applications.
                      </p>
                      <p align="justify" class="add-bottom">
			 The reviewer for the Journal of Energy Storage, Displays, Optics Communications, Measurement, Applied Soft Computing, and Scientific Reports.
                      </p>
		    </div>
             </div>
         </div>

      </div> <!-- Row End-->

   <!--/section> <!-- Publication Section End-->	   

   <!--<section id="teaching">

    <div class="row add-bottom">

         <div class="twelve columns">

            <h1 align="center">Teaching</h1>
            <hr>   
  
            <div class="row add-bottom">
                    <div class="twelve columns">
		      <p align="justify" class="add-bottom">
			 Research Intern | Tencent Youtu Lab, Tencent, Shanghai, China | Feb. 2021 – Jun. 2021.
			 (Advisor: Yuqiang Ren.  Topic: Object Detection.)
                      </p> 
                      <p align="justify" class="add-bottom">
                         Visiting Scholar | The Chinese University of Hong Kong, Hongkong, China | Nov. 2022 – May. 2023.
			 (Advisor: Hongliang Ren.  Topic: Industrial Robot.)
                      </p>    
		    </div>
             </div>
         </div>

      </div> <!-- Row End-->

   <!--/section> <!-- Publication Section End-->	   
	   
   <section id="award">

    <div class="row add-bottom">

         <div class="twelve columns">

            <h1 align="center">Awards</h1>
            <hr>   
  
            <div class="row add-bottom">
                    <div class="twelve columns">
		      <p align="justify" class="add-bottom">
			 The Program B for Outstanding PhD candidate of Nanjing University (2020)
                      </p>    
                      <p align="justify" class="add-bottom">
			 China Telecom Scholarship (2017) (Only 1700 students receive this honor annually in China.)
                      </p>
                      <p align="justify" class="add-bottom">
			 National Scholarship for Graduate Students (2016, 2015)
                      </p>
                      <p align="justify" class="add-bottom">
			 Top Award in the 10th “Challenge Cup” Hubei College Students’ Extracurricular Academic Science and Technology Works Contest (2015)
                      </p>
                      <p align="justify" class="add-bottom">
                         Gold Award in the Progressive Innovation Award of the 15th “Challenge Cup” National College Students’ Extracurricular Academic Science and Technology Works Contest (2013)                      </p>
		    </div>
                </div>

              </div>
            <hr>
         </div>

      </div> <!-- Row End-->

   </section> <!-- Publication Section End-->
	
	<small> Last modified: Feb. 12, 2024 </small>
	<p>
        <small> Template from <a href="http://www.Styleshout.com">http://www.Styleshout.com</a> </small>
        </p>
	<!--<small> <span id="busuanzi_container_site_pv">
                    Total page views <span id="busuanzi_value_site_pv" class="white-color"></span>
        </span>
        <span id="busuanzi_container_site_uv">
                    ,&nbsp; number of visitors <span id="busuanzi_value_site_uv" class="white-color"></span>.
        </span></small>--!>
   <!-- Java Script
   ================================================== -->
   <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
   <script>window.jQuery || document.write('<script src="js/jquery-1.10.2.min.js"><\/script>')</script>
   <script type="text/javascript" src="js/jquery-migrate-1.2.1.min.js"></script>
   <script async src="js/busuanzi.pure.mini.js"></script>

   <script src="js/jquery.flexslider.js"></script>
   <script src="js/waypoints.js"></script>
   <script src="js/jquery.fittext.js"></script>
   <script src="js/magnific-popup.js"></script>
   <script src="js/init.js"></script>
   <script>
  	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-105425042-1', 'auto');
  	ga('send', 'pageview');
  </script>

<div style='width:400px;height:200px;margin:0 auto'>
<!--<a href="https://clustrmaps.com/site/1b7cl" title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=wHZzsZcsBCB6HxOqmaDqDJX5oLT_yvrQ5HQx9agcvJo&cl=ffffff"></a>-->
<!--<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=wHZzsZcsBCB6HxOqmaDqDJX5oLT_yvrQ5HQx9agcvJo&cl=ffffff&w=a"></script>-->
<!--<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=ItPniLpvAlUyBKssdgFtKwBDg8lP1ao3ju4dmDzw6uA&cl=ffffff&w=a"></script>-->
<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=tTMsWaOSBm1xJqnOZFCRHWyemYimfkjn01seRPaBtyw&cl=ffffff&w=a"></script></div>

</body>

</html>
