<!DOCTYPE html>
<!--[if lt IE 8 ]><html class="no-js ie ie7" lang="en"> <![endif]-->
<!--[if IE 8 ]><html class="no-js ie ie8" lang="en"> <![endif]-->
<!--[if (gte IE 8)|!(IE)]><!--><html class="no-js" lang="en"> <!--<![endif]-->
<head>

   <!--- Basic Page Needs
   ================================================== -->
  <meta charset="utf-8">
	<title>Yang Zhang</title>
	<meta name="description" content="Research and Personal Projects">
	<meta name="author" content="anurag">

   <!-- Mobile Specific Metas
   ================================================== -->
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<!-- CSS
    ================================================== -->
   <link rel="stylesheet" href="css/default.css">
	 <link rel="stylesheet" href="css/layout.css">
   <link rel="stylesheet" href="css/academicons/css/academicons.css"/>
   <link rel="stylesheet" href="css/media-queries.css">
   <link rel="stylesheet" href="css/magnific-popup.css">

   <!-- Script
   ================================================== -->
	<script src="js/modernizr.js"></script>


</head>

<body>


   <!-- About Section
   ================================================== -->
   <section id="about">
      <nav id="nav-wrap">

        <a class="mobile-btn" href="#nav-wrap" title="Show navigation">Show navigation</a>
	      <a class="mobile-btn" href="#" title="Hide navigation">Hide navigation</a>

         <ul id="nav" class="nav">
            <li class="current"><a class="smoothscroll" href="#about">About</a></li>
            <li><a class="smoothscroll" href="#biography">Biography</a></li>
            <li><a class="smoothscroll" href="#publication">Publications</a></li>
            <!--li><a class="smoothscroll" href="#research">Research</a></li-->

         </ul> <!-- end #nav -->

      </nav> <!-- end #nav-wrap -->

      <div class="row">

         <div class="three columns">

            <img class="profile-pic"  src="media/Yangzhang.jpg" alt="" />

         </div>

         <div class="nine columns main-col">

            <h1><font color="white">Yang Zhang</font></h1>

            <h5> <font color="white"> Ph.D. Candidate, Multimedia and Computer Vision </font> </h5>
            <h5> <font color="white"> National Key Laboratory for Novel Software Technology </font> </h5>
            <h5> <font color="white"> Department of Computer Science and Technology, Nanjing University </font> </h5>
		 <font color="white"> yzhangcst_at_smail.nju.edu.cn; yzhangcst_at_gmail.com  </font>
            <footer>
              <div class="row">

               <div class="nine columns">
                  <ul class="social-links">
                     <li><a href="https://scholar.google.com/citations?user=lgXDV5cAAAAJ&hl=zh-CN&citsig=AMD79oorCUy1KxBXSEYZK76Eo9el2mvzGA" target="_blank"><i class="fa fa-google-scholar"></i></a></li>
                     <li><a href="https://github.com/Yangzhangcst" target="_blank"><i class="fa fa-github"></i></a></li>
                  </ul>
               </div>
              </div>
            </footer>
         </div>

     </div> <!-- end .main-col -->

      </div>

      <p class="scrolldown">
         <a class="smoothscroll" href="#about"><i class="icon-down-circle"></i></a>
      </p>
 </div>
</section> 

   <section id="biography">
	
    <div class="row add-bottom">

         <div class="twelve columns">

            <h1 align="center">Biography</h1>
            <hr>
            <div class="row add-bottom">

   <p class="lead">
     I am currently pursuing the Ph.D. degree in the National Key Laboratory for Novel Software Technology, 
     Department of Computer Science and Technology, Nanjing University with <a href="https://cs.nju.edu.cn/ywguo/">Yanwen Guo.</a>
     My current research interests are machine learning and computer vision including object detection, image segmentation, 
     semantic segmentation for RGBD images. My full Chinese CV is available <a href="media/CV.pdf" target="_blank" title="CV"> here </a>.
   </p>
   <p>
     I received the B.S. degree and the M.S. degree with <a href="https://tsme.hbut.edu.cn/info/1013/2082.htm">Guodong Sun</a> from
     Hubei University of Technology in 2014 and 2017 respectively. 
   </p>
 </div>
</section>
	    
   <!--Publication Section
   ================================================== -->
   <section id="publication">

    <div class="row add-bottom">

         <div class="twelve columns">

            <h1 align="center">Publications</h1>
            <hr>
            <div class="row add-bottom">
              <h2 align=center> Attacking Optical Flow</h2>
              <p align="center", class="lead add-bottom">
                Anurag Ranjan, Joel Janai, Andreas Geiger, Michael J. Black (ICCV 2019)
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/flow_attack.jpg" >
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                        Deep learning based optical flow methods are vulnerable to adversarial attacks. We show that it is very easy to attack these systems in real world by just placing a small printed patch in the scene.
                      </p>
                      <p class="paper-links" align="center"> <a href="https://flowattack.is.tuebingen.mpg.de/" target="_blank" title="Project Page"><i class="fa fa-external-link"></i></a>
                        <a href="https://github.com/anuragranj/flowattack" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="http://arxiv.org/abs/1910.10053" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>

            <hr>
            <div class="row add-bottom">
              <h2 align=center> Competitive Collaboration</h2>
              <h3 align=center> Joint Unsupervised Learning of Depth, Camera <br> Motion, Optical Flow and Motion Segmentation </h3>
              <p align="center", class="lead add-bottom">
                Anurag Ranjan, Varun Jampani, Kihwan Kim, Deqing Sun, Jonas Wulff, Michael J. Black (CVPR 2019)
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/ac_tease.jpg" >
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                        We address the unsupervised learning of several interconnected problems in low-level vision: single view depth prediction, camera motion estimation, optical flow and segmentation
                        of a video into the static scene and moving regions. Our model is trained without any supervision and achieves state of the art results amongst unsupervised methods.
                      </p>
                      <p class="paper-links" align="center"> <a href="https://ps.is.tuebingen.mpg.de/publications/adversarial-collaboration" target="_blank" title="Project Page"><i class="fa fa-external-link"></i></a>
                        <a href="https://github.com/anuragranj/ac" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://arxiv.org/abs/1805.09806" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr>

            <div class="row add-bottom">
              <h2 align=center> Capture, Learning and Synthesis of 3D Speaking Styles </h2>
              <p align="center", class="lead add-bottom">
                Daniel Cudeiro*, Timo Bolkart*, Cassidy Laidlaw, Anurag Ranjan, Michael J. Black (CVPR 2019)
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/VOCA.jpg" >
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                      A neural network for generating 3D facial motion by using raw speech audio. Works on a veriety of unseen faces.
                      </p>
                      <p class="paper-links" align="center"> <a href="http://voca.is.tue.mpg.de" target="_blank" title="Project Page"><i class="fa fa-external-link"></i></a>
                        <a href="http://voca.is.tue.mpg.de" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://ps.is.tue.mpg.de/publications/voca2019" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr>

            <div class="row add-bottom">
              <h2 align=center> Generating 3D Faces using Convolutional Mesh Autoencoders </h2>
              <p align="center", class="lead add-bottom">
                Anurag Ranjan, Timo Bolkart, Soubhik Sanyal, Michael J. Black (ECCV 2018)
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/coma_faces.jpg" >
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                      A non-linear model for generating 3D faces using a Convolutional Autoencoder that operates directly on meshes. Our model is state of the art in generating diverse
                      range of 3D facial meshes.
                      </p>
                      <p class="paper-links" align="center"> <a href="http://coma.is.tue.mpg.de" target="_blank" title="Project Page"><i class="fa fa-external-link"></i></a>
                        <a href="https://github.com/anuragranj/coma" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://arxiv.org/pdf/1807.10267.pdf" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr>

            <div class="row add-bottom">
              <h2 align=center> Unsupervised Learning of Multi-Frame Optical Flow with Occlusions </h2>
              <p align="center", class="lead add-bottom">
                Joel Janai, Fatma Güney, Anurag Ranjan, Michael J. Black and Andreas Geiger (ECCV 2018)
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="https://ps.is.tue.mpg.de/uploads/publication/image/20263/thumb_lg_joeleccv18.png" >
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                        We propose a framework for unsupervised learning of optical flow and occlusions over multiple frames. Our multi-frame, occlusion-sensitive formulation outperforms existing unsupervised two-frame methods and even produces results on par with some fully supervised methods.
                      </p>
                      <p class="paper-links" align="center"> <a href="https://ps.is.tue.mpg.de/publications/janai2018eccv" target="_blank" title="Project Page"><i class="fa fa-external-link"></i></a>
                        <a href="http://www.cvlibs.net/projects.php"" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="http://www.cvlibs.net/publications/Janai2018ECCV.pdf" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr>

            <div class="row add-bottom">
              <h2 align=center> Learning Human Optical Flow </h2>
              <p align="center", class="lead add-bottom">
                Anurag Ranjan, Javier Romero, Michael J. Black (BMVC 2018)
              </p>

                  <div class="row"> <div class="five columns">
                    <iframe width="420" height="200" src="https://www.youtube.com/embed/IFZbsDt9jMw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                        Learning optical flow for humans is difficult. So, we created a synthetic dataset with realistic humans and trained a neural network on it.
                      </p>
                      <p class="paper-links" align="center"> <a href="http://humanflow.is.tue.mpg.de" target="_blank" title="Project Page"><i class="fa fa-external-link"></i></a>
                        <a href="https://github.com/anuragranj/humanflow" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://arxiv.org/abs/1806.05666" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr>

            <div class="row add-bottom">
              <h2 align=center> SPyNet: Spatial Pyramid Network for Optical Flow </h2>
              <p align="center", class="lead add-bottom">
                Anurag Ranjan, Michael J. Black (CVPR 2017)
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/sintel_pyramid.jpg" >
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                        SPyNet is the smallest deep network in the world that computes optical flow. It is smaller than Flownet by 97% and outperforms it significanly. Both code and trained models are available.
                      </p>
                      <p class="paper-links" align="center"> <a href="http://spynet.is.tue.mpg.de" target="_blank" title="Project Page"><i class="fa fa-external-link"></i></a>
                        <a href="https://github.com/anuragranj/spynet" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://arxiv.org/abs/1611.00850" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr>

            <div class="row add-bottom">
              <h2 align=center> Interactive Gaze Driven Animation of the Eye Region </h2>
              <p align="center", class="lead add-bottom">
                Debanga R Neog, João L Cardoso, Anurag Ranjan, Dinesh K Pai (Web3D 2016)
              </p>

                  <div class="row"> <div class="five columns">
                    <iframe width="420" height="200" src="https://www.youtube.com/embed/FSae6RVllwQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                        A system for real-time animation of eyes that can be interactively controlled in a WebGL. This is the first system for real-time animation of soft tissue movement around the eyes based on gaze input.                      </p>
                      <p class="paper-links" align="center"> <a href="http://www.cs.ubc.ca/research/eyemoveweb3d16/" target="_blank" title="Project Page"><i class="fa fa-external-link"></i></a>
                      <a href="http://www.cs.ubc.ca/research/eyemoveweb3d16/Interactive%20Gaze%20Driven%20Animation%20of%20the%20Eye%20Region.pdf" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr>

            <div class="row add-bottom">
              <h2 align=center> Learning Periorbital Soft Tissue Motion </h2>
              <p align="center", class="lead add-bottom">
                Anurag Ranjan (Master's Thesis, UBC 2015)
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/periorbit.jpg" >
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                        We model the soft tissues around the eyes that are associated with subtle and fast motions and convey emotions during facial expressions. Our data driven model that can efficiently learn and reproduce the complex motion of these periorbital soft tissues.
                        <p class="paper-links" align="center"> <a href="https://open.library.ubc.ca/cIRcle/collections/ubctheses/24/items/1.0166703" target="_blank" title="Project Page"><i class="fa fa-external-link"></i></a>
                        <a href="media/Learning_Periorbital_Soft_Tissue_Motion.pdf" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr>

            <div class="row add-bottom">
              <h2 align=center> Implementation of 3D object recognition and tracking </h2>
              <p align="center", class="lead add-bottom">
                Pankaj Bongale, Anurag Ranjan, Sahil Anand (RACSS 2012)
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/obj_recog_pcl.jpg" >
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                        This object recognition and tracking system utilizes the depth information from a low-cost depth sensor. This approach makes use of the depth information and 3d properties of objects inorder to accurately identify them independent of lighting conditions.
                        <p class="paper-links" align="center">
                        <a href="media/object_recognition_point_clouds.pdf" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr>

         </div>

      </div> <!-- Row End-->

   </section> <!-- Research Section End-->

  <small> Template from <a href="http://www.Styleshout.com">http://www.Styleshout.com</a> </small>
   <!-- Java Script
   ================================================== -->
   <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
   <script>window.jQuery || document.write('<script src="js/jquery-1.10.2.min.js"><\/script>')</script>
   <script type="text/javascript" src="js/jquery-migrate-1.2.1.min.js"></script>

   <script src="js/jquery.flexslider.js"></script>
   <script src="js/waypoints.js"></script>
   <script src="js/jquery.fittext.js"></script>
   <script src="js/magnific-popup.js"></script>
   <script src="js/init.js"></script>
   <script>
  	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-105425042-1', 'auto');
  	ga('send', 'pageview');
  </script>

</body>

</html>
